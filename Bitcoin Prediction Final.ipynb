{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime as dt, timedelta\n",
    "start_date = dt(2016, 1, 30, 0, 0, 0) #best results when train from 4/2016 and onward # maybe do small window retraining\n",
    "end_date = dt(2016, 11, 23, 0, 0, 0)\n",
    "price_window = 350\n",
    "tweet_window = 250\n",
    "min_tweets = 1\n",
    "cutoff = .25\n",
    "retweets_min = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data_new.csv', parse_dates=['Date','Date_Time'])\n",
    "start_index = df[df['Date'] == start_date].iloc[[0]].index.values[0]\n",
    "df = df[start_index:]\n",
    "df = df.set_index(['Date_Time'])\n",
    "df = df[start_date:]\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def getNearest(t, df):\n",
    "    i = df.index.searchsorted(t)\n",
    "    return df.iloc[i]['Price'] #df.ix[df.index[i]]['Price']\n",
    "\n",
    "def getDelta(df, date, delta_minutes, cutoff):\n",
    "    df2 = df[:-(2*delta_minutes)]\n",
    "    date = np.datetime64(date)\n",
    "    delta_minutes = np.timedelta64(delta_minutes,'m')\n",
    "    m = getNearest(date + delta_minutes, df2) - getNearest(date, df2)\n",
    "    if m > cutoff: return 2\n",
    "    if m < -cutoff: return 0\n",
    "    return 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 17139 instances of 350 minute periods, The percent pos is: 0.5329949238578681\n"
     ]
    }
   ],
   "source": [
    "#get percent of increases \n",
    "df2 = df[:-(5*price_window)]\n",
    "number_samples = int(len(df2)/25)\n",
    "dlist = np.random.choice(df2.index.values, number_samples)\n",
    "dlist = [getDelta(df, d, price_window, 0) for d in dlist]\n",
    "dlist_count = Counter(dlist)\n",
    "nonTweet_percentPos = dlist_count[2]/(number_samples - dlist_count[1])\n",
    "print('For', number_samples, 'instances of', price_window, 'minute periods, The percent pos is:', nonTweet_percentPos)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_i_like = ['bitcoin', 'btc', 'blockchain', 'litecoin', 'usd',\n",
    "'wallet', 'currency', 'altcoin', 'mining', 'gox', 'mt', 'crypto', 'new', \n",
    "'cryptocurrency', 'ethereum', 'fintech', 'ltc', 'free', 'digital', 'latest',\n",
    "'money', 'bank', 'hardware', 'index', 'satoshi', 'market', 'economy', 'bitcoins',\n",
    "'dogecoin', 'value', 'secure', 'miner', 'trading', 'coindesk', 'smart', \n",
    "'bitstamp', 'technology', 'euro', 'buy', 'trade', \n",
    "'coinbase', 'power', 'time', 'tech', 'trezor', 'bitfinex', 'algorithm', 'china', 'banks', \n",
    "'earn', 'past', 'landbitcoin', 'portal', 'win',\n",
    " 'data', 'coin', 'best', 'cash', 'bitcoinnews', 'increased', 'cloud', 'average', \n",
    "'future', 'change', 'financial', 'virtual', 'startup', 'open', 'ceo', 'platform', \n",
    "'decreased', 'business', 'finance', 'convert', 'high', 'dash', 'altcoins', 'currencies', \n",
    "'collapse', 'libertarian', 'bot', 'dollar', 'movement', 'directly', 'game',\n",
    "'global', 'technical', 'investment', 'launches', 'volume', 'network', 'support',\n",
    "'observer', 'lost', 'security', 'secure', 'won', 'good', 'launch', \n",
    "'gambling', 'japan', 'invest', 'sell', 'wild', 'hack', \n",
    "'pay', 'exchanges', 'miners', 'crypto-currencies', 'forum', 'fast', 'sell', 'ledger', \n",
    "'mobile', 'grow', 'hot', 'great', 'wild', 'hack', 'miracle', 'bullish', 'solution', 'millionare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9  0.2]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from textblob import TextBlob\n",
    "\n",
    "#TODO: try grabbing each minute seperately\n",
    "\n",
    "def singleTweetFV(tweet_text, retweets):\n",
    "    words = [w.lstrip('#') for w in tweet_text.lower().split(' ')]\n",
    "    counts = Counter(words)\n",
    "    fv = np.zeros(len(words_i_like))\n",
    "    for i, word in enumerate(words_i_like): fv[i] = counts[word]\n",
    "    fv *= (retweets + 1)\n",
    "    return fv\n",
    "\n",
    "def sentimentTweet(tweet_text):\n",
    "    b = TextBlob(tweet_text)\n",
    "    fv = np.array([b.sentiment.subjectivity, 1 + b.sentiment.polarity])\n",
    "    return fv\n",
    "\n",
    "print(sentimentTweet(\"I hate this\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from pymongo import MongoClient\n",
    "# twitter_start_date = start_date + timedelta(days=1)\n",
    "\n",
    "# db = MongoClient(\"mongodb://104.236.1.250:27017\")['local']\n",
    "# collection = db['twitter_two']\n",
    "# print('regular grabbing tweets')\n",
    "# tweets = list(collection.find({\"date\": {\"$gt\": twitter_start_date, \"$lt\": end_date}, \"retweets\": {\"$gte\":retweets_min}}))\n",
    "# print('# of tweets grabbed:', len(tweets))\n",
    "# print(tweets[1:10])\n",
    "\n",
    "# def buildFVs(df, tweets, price_window, tweet_window, min_tweets, cutoff):\n",
    "#     mFV = np.zeros(len(words_i_like))\n",
    "#     date = tweets[0]['date']\n",
    "#     last_date = df['Date'][-1] - timedelta(days=1)\n",
    "#     tweet_count = 0\n",
    "#     fvs = []\n",
    "#     targetdata =[]\n",
    "#     most_recent = []\n",
    "#     counts = []\n",
    "    \n",
    "#     for tweet in tweets:\n",
    "#         tFV = singleTweetFV(tweet['text'], tweet['retweets'])\n",
    "#         if date.minute - tweet['date'].minute == 0:\n",
    "#             mFV += tFV\n",
    "#             tweet_count +=1\n",
    "#         else:\n",
    "#             if tweet_count > min_tweets:\n",
    "#                 if date > last_date: break # return fvs, targetdata\n",
    "#                 most_recent.append(mFV)\n",
    "#                 if len(most_recent) > tweet_window:\n",
    "#                     most_recent.pop(0) \n",
    "#                     fvs.append(sum(most_recent))\n",
    "#                     targetdata.append(getDelta(df, np.datetime64(date), price_window, cutoff))\n",
    "#                     counts.append(tweet_count)\n",
    "#             mFV = np.zeros(len(words_i_like))\n",
    "#             date = tweet['date']\n",
    "#             tweet_count = 0\n",
    "#     return fvs, targetdata\n",
    "\n",
    "# fvs, target_data = buildFVs(df, tweets, price_window, tweet_window, min_tweets, cutoff)\n",
    "\n",
    "# print('lenght of target data:', len(target_data))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "version 2 of bitcoin collector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': ObjectId('58719e2a220fec32f1a79a7c'), 'myid': 'hi'}]\n"
     ]
    }
   ],
   "source": [
    "# set up db\n",
    "from pymongo import MongoClient\n",
    "\n",
    "db = MongoClient(\"mongodb://104.236.1.250:27017\")['bitcoin_scraped']\n",
    "db.authenticate('meir', 'PreemPalver', source='bitcoin_scraped')\n",
    "collection = db['scraped1']\n",
    "tweets = list(collection.find({}))\n",
    "print(tweets)\n",
    "# collection = db['twitter_two_modified_agg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping:  2016-01-30 00:00:00 2016-02-27 00:00:00\n",
      "0\n",
      "scraping:  2016-02-27 00:00:00 2016-03-26 00:00:00\n",
      "0\n",
      "scraping:  2016-03-26 00:00:00 2016-04-23 00:00:00\n",
      "0\n",
      "scraping:  2016-04-23 00:00:00 2016-05-21 00:00:00\n",
      "0\n",
      "scraping:  2016-05-21 00:00:00 2016-06-18 00:00:00\n",
      "0\n",
      "scraping:  2016-06-18 00:00:00 2016-07-16 00:00:00\n",
      "0\n",
      "scraping:  2016-07-16 00:00:00 2016-08-13 00:00:00\n",
      "0\n",
      "scraping:  2016-08-13 00:00:00 2016-09-10 00:00:00\n",
      "0\n",
      "scraping:  2016-09-10 00:00:00 2016-10-08 00:00:00\n",
      "0\n",
      "scraping:  2016-10-08 00:00:00 2016-11-05 00:00:00\n",
      "0\n",
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "def scrape_window(start_date, end_date):\n",
    "    print('scraping: ', start_date, end_date)\n",
    "    twitter_start_date = start_date + timedelta(days=1)\n",
    "    tweets = list(collection.find({\"_id\": {\"$gt\": twitter_start_date, \"$lt\": end_date}}).sort([(\"_id\", 1)]))\n",
    "    print(len(tweets))\n",
    "#     print('length::', len(tweets))\n",
    "#     for i in tweets[0:20]:\n",
    "#         print(i)\n",
    "    return tweets\n",
    "    \n",
    "def monthRange(start_date, end_date):\n",
    "    week = timedelta(weeks=1)\n",
    "    for n in range(int ((end_date - start_date)/week))[::4]:\n",
    "\n",
    "        yield start_date + timedelta(weeks=n)\n",
    "\n",
    "def buildfvs(start_date, last_date):\n",
    "    fvs = []\n",
    "    targetdata =[]\n",
    "    most_recent = []\n",
    "    counter = 0\n",
    "\n",
    "    for month in monthRange(start_date, last_date):\n",
    "        monthFV = []\n",
    "        monthTarget = []\n",
    "        for tweet_min in scrape_window(month, month + timedelta(weeks=4)):\n",
    "            count = tweet_min['count']\n",
    "            date = tweet_min['_id']\n",
    "            if count  < min_tweets: continue\n",
    "            mFV = np.array([count, tweet_min['retweets_total']])\n",
    "            for tweet_text, retweets in zip(tweet_min['text'], tweet_min['retweets']):\n",
    "                if retweets >= retweets_min:\n",
    "                    sent = np.zeros(2)   \n",
    "                    sent += sentimentTweet(tweet_text) # fix sentiment, seems too negative\n",
    "                    words = np.zeros(len(words_i_like))  \n",
    "                    words += singleTweetFV(tweet_text, retweets)\n",
    "#             print(sent/count)\n",
    "#             mFV = np.concatenate((sent/count, mFV, words))\n",
    "            mFV = words\n",
    "            most_recent.append((mFV, date))\n",
    "#             counter +=1\n",
    "#             first = most_recent[0][1]\n",
    "#             print(len(most_recent))\n",
    "#             while date - first > timedelta(minutes=tweet_window):\n",
    "#                 print(date, first, date - first)\n",
    "#                 print(timedelta(minutes=tweet_window))\n",
    "#                 most_recent.pop(0) \n",
    "#                 first = most_recent[0][1]\n",
    "            l = len(most_recent) \n",
    "            if l > tweet_window:\n",
    "                most_recent.pop(0)\n",
    "                sum_month = sum([x[0] for x in most_recent])\n",
    "#                 sum_month[0] = sum_month[0]/l\n",
    "#                 sum_month[1] = sum_month[1]/l\n",
    "                monthFV.append(sum_month)\n",
    "                monthTarget.append(getDelta(df, np.datetime64(date), price_window, cutoff))\n",
    "        fvs.append(monthFV)\n",
    "        targetdata.append(monthTarget)\n",
    "\n",
    "    return (fvs, targetdata)\n",
    "\n",
    "\n",
    "# start_date = dt(2014, 1, 1, 0, 0, 0)\n",
    "last_date = dt(2016, 10, 23, 0, 0, 0) - timedelta(days=1)\n",
    "\n",
    "fvs, targetdata = buildfvs(start_date, last_date)\n",
    "print(len(fvs))\n",
    "print(len(targetdata))\n",
    "\n",
    "# %lprun -f buildfvs buildfvs(start_date, last_date)\n",
    "# %lprun -f getDelta getDelta(df, np.datetime64(date), price_window, cutoff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1cdd3878c2dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtdc\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msplit_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetdata_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtarget_up\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtdc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mlarge_target_up\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetdata_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetdata_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "def split_list(a_list):\n",
    "    third = int(len(a_list)/3)\n",
    "    return a_list[:third], a_list[third:2*third], a_list[2*third:],\n",
    "\n",
    "fvs_new = [item for sublist in fvs for item in sublist]\n",
    "targetdata_new = [item for sublist in targetdata for item in sublist]\n",
    "fva, fvb, fvc = split_list(fvs_new)\n",
    "tda, tdb, tdc= split_list(targetdata_new)\n",
    "\n",
    "target_up = [(sum(tda)/len(tdb))/2, (sum(tdb)/len(tdb))/2, (sum(tdc)/len(tdb))/2]\n",
    "large_target_up = (sum(targetdata_new)/len(targetdata_new))/2\n",
    "\n",
    "print(len(fva))\n",
    "print(fva[:5])\n",
    "print(tda[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "modeltype = LogisticRegression()\n",
    "\n",
    "guessedup = 0\n",
    "clf = modeltype.fit(fva, tda)\n",
    "pred = clf.predict(fvb)\n",
    "print(len(pred))\n",
    "\n",
    "count = total = 0\n",
    "for i, x in enumerate(pred):\n",
    "    if x != 1 and tdb[i] != 1:\n",
    "        count += 1\n",
    "        if x == 2: guessedup+=1\n",
    "        if x == tdb[i]: total += 1\n",
    "            \n",
    "log_reg = [\"Logistic Regression\", pred.mean()/2,  total/count, (len(pred) - count)/len(pred)]            \n",
    "\n",
    "modeltype = MultinomialNB()\n",
    "\n",
    "guessedup = 0\n",
    "clf = modeltype.fit(fva, tda)\n",
    "pred = clf.predict(fvb)\n",
    "\n",
    "count = total = 0\n",
    "for i, x in enumerate(pred):\n",
    "    if x != 1 and tdb[i] != 1:\n",
    "        count += 1\n",
    "        if x == 2: guessedup+=1\n",
    "        if x == tdb[i]: total += 1\n",
    "if count == 0: count = 1\n",
    "# print(len(pred))\n",
    "mnbayes = [\"MultinomialNB\", pred.mean()/2,  total/count, (len(pred) - count)/len(pred)]            \n",
    "\n",
    "modeltype = RandomForestClassifier(n_estimators=500)\n",
    "\n",
    "guessedup = 0\n",
    "clf = modeltype.fit(fva, tda)\n",
    "pred = clf.predict(fvb)\n",
    "\n",
    "count = total = 0\n",
    "for i, x in enumerate(pred):\n",
    "    if x != 1 and tdb[i] != 1:\n",
    "        count += 1\n",
    "        if x == 2: guessedup+=1\n",
    "        if x == tdb[i]: total += 1\n",
    "\n",
    "randtrees = [\"RandomForestClassifier\", pred.mean()/2,  total/count, (len(pred) - count)/len(pred)]       \n",
    "\n",
    "print('======== Tuning ========')\n",
    "print('start date: ', start_date)\n",
    "print('price window =  minutes after tweet: ', price_window) # '. minutes before:', MINUTES_BEFORE)\n",
    "print('tweet window = number of tweets looked at: ', tweet_window)\n",
    "print('minimum tweets in minute: ', min_tweets)\n",
    "print('minimum retweets: ', retweets_min)\n",
    "print('cutoff:', cutoff)\n",
    "print('tweet_accuracy', large_target_up)\n",
    "print('========================')\n",
    "\n",
    "print(\"percent of bitcoin increases over time\", nonTweet_percentPos)\n",
    "print(\"percentage of target up:\", target_up)\n",
    "\n",
    "for c in [log_reg, mnbayes, randtrees]:\n",
    "    print('\\n')\n",
    "    print(c[0])\n",
    "    print(\"percentage of predictions up:\", c[1])\n",
    "    print('percent_accurate:', c[2])\n",
    "    print('(amount removed:', str(c[3]) + '%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
